var documenterSearchIndex = {"docs":
[{"location":"embed/#embedding","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"","category":"section"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"A timeseries recorded in some manner from a dynamical system can be used to gain information about the dynamics of the entire state space of the system. This can be done by constructing a new state space from the timeseries. One method that can do this is what is known as delay coordinates embedding or delay coordinates reconstruction.","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"The main functions to use for embedding some input data are embed or genembed. Both functions return a StateSpaceSet.","category":"page"},{"location":"embed/#Timeseries-embedding","page":"Delay coordinates embedding","title":"Timeseries embedding","text":"","category":"section"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"embed","category":"page"},{"location":"embed/#DelayEmbeddings.embed","page":"Delay coordinates embedding","title":"DelayEmbeddings.embed","text":"embed(s, d, τ [, h])\n\nEmbed s using delay coordinates with embedding dimension d and delay time τ and return the result as a StateSpaceSet. Optionally use weight h, see below.\n\nHere τ > 0, use genembed for a generalized version.\n\nDescription\n\nIf τ is an integer, then the n-th entry of the embedded space is\n\n(s(n) s(n+tau) s(n+2tau) dots s(n+(d-1)tau))\n\nIf instead τ is a vector of integers, so that length(τ) == d-1, then the n-th entry is\n\n(s(n) s(n+tau1) s(n+tau2) dots s(n+taud-1))\n\nThe resulting set can have same invariant quantities (like e.g. Lyapunov exponents) with the original system that the timeseries were recorded from, for proper d and τ. This is known as the Takens embedding theorem [Takens1981] [Sauer1991]. The case of different delay times allows embedding systems with many time scales, see[Judd1998].\n\nIf provided, h can be weights to multiply the entries of the embedded space. If h isa Real then the embedding is\n\n(s(n) h cdot s(n+tau) h^2 cdot s(n+2tau) dotsh^d-1 cdot s(n+γtau))\n\nOtherwise h can be a vector of length d-1, which the decides the weights of each entry directly.\n\nReferences\n\n[Takens1981] : F. Takens, Detecting Strange Attractors in Turbulence — Dynamical Systems and Turbulence, Lecture Notes in Mathematics 366, Springer (1981)\n\n[Sauer1991] : T. Sauer et al., J. Stat. Phys. 65, pp 579 (1991)\n\n[Judd1998]: K. Judd & A. Mees, Physica D 120, pp 273 (1998)\n\n[Farmer1988]: Farmer & Sidorowich, Exploiting Chaos to Predict the Future and Reduce Noise\"\n\n\n\n\n\n","category":"function"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"note: Embedding discretized data values\nIf the data values are very strongly discretized (e.g., integers or floating-point numbers with very small bits), this can result to distances between points in the embedded space being 0. This is problematic for several library functions. Best practice here is to add noise to your original timeseries before embedding, e.g., s = s .+ 1e-15randn(length(s)).","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"Here are some examples of embedding a 3D continuous chaotic system:","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"using DelayEmbeddings\n\nx = cos.(0:0.1:1)","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"embed(x, 3, 1)","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"note: `τ` and `Δt`\nKeep in mind that whether a value of τ is \"reasonable\" for continuous time systems depends on the sampling time Δt.","category":"page"},{"location":"embed/#Embedding-Structs","page":"Delay coordinates embedding","title":"Embedding Structs","text":"","category":"section"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"The high level function embed utilizes a low-level interface for creating embedded vectors on-the-fly. The high level interface simply loops over the low level interface.","category":"page"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"DelayEmbedding\nτrange","category":"page"},{"location":"embed/#DelayEmbeddings.DelayEmbedding","page":"Delay coordinates embedding","title":"DelayEmbeddings.DelayEmbedding","text":"DelayEmbedding(γ, τ, h = nothing) → `embedding`\n\nReturn a delay coordinates embedding structure to be used as a function-like-object, given a timeseries and some index. Calling\n\nembedding(s, n)\n\nwill create the n-th delay vector of the embedded space, which has γ temporal neighbors with delay(s) τ. γ is the embedding dimension minus 1, τ is the delay time(s) while h are extra weights, as in embed for more.\n\nBe very careful when choosing n, because @inbounds is used internally. Use τrange!\n\n\n\n\n\n","category":"type"},{"location":"embed/#DelayEmbeddings.τrange","page":"Delay coordinates embedding","title":"DelayEmbeddings.τrange","text":"τrange(s, de::AbstractEmbedding)\n\nReturn the range r of valid indices n to create delay vectors out of s using de.\n\n\n\n\n\n","category":"function"},{"location":"embed/#Generalized-embeddings","page":"Delay coordinates embedding","title":"Generalized embeddings","text":"","category":"section"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"genembed\nGeneralizedEmbedding","category":"page"},{"location":"embed/#DelayEmbeddings.genembed","page":"Delay coordinates embedding","title":"DelayEmbeddings.genembed","text":"genembed(s, τs, js = ones(...); ws = nothing) → ssset\n\nCreate a generalized embedding of s which can be a timeseries or arbitrary StateSpaceSet, and return the result as a new StateSpaceSet.\n\nThe generalized embedding works as follows:\n\nτs denotes what delay times will be used for each of the entries of the delay vector. It is recommended that τs[1] = 0. τs is allowed to have negative entries as well.\njs denotes which of the timeseries contained in s will be used for the entries of the delay vector. js can contain duplicate indices.\nws are optional weights that weight each embedded entry (the i-th entry of the   delay vector is weighted by ws[i]). If provided, it is recommended that ws[1] == 1.\n\nτs, js, ws are tuples (or vectors) of length D, which also coincides with the embedding dimension. For example, imagine input trajectory s = x y z where x y z are timeseries (the columns of the StateSpaceSet). If js = (1, 3, 2) and τs = (0, 2, -7) the created delay vector at each step n will be\n\n(x(n) z(n+2) y(n-7))\n\nUsing ws = (1, 0.5, 0.25) as well would create\n\n(x(n) frac12 z(n+2) frac14 y(n-7))\n\njs can be skipped, defaulting to index 1 (first timeseries) for all delay entries, while it has no effect if s is a timeseries instead of a StateSpaceSet.\n\nSee also embed. Internally uses GeneralizedEmbedding.\n\n\n\n\n\n","category":"function"},{"location":"embed/#DelayEmbeddings.GeneralizedEmbedding","page":"Delay coordinates embedding","title":"DelayEmbeddings.GeneralizedEmbedding","text":"GeneralizedEmbedding(τs, js = ones(length(τs)), ws = nothing) -> `embedding`\n\nReturn a delay coordinates embedding structure to be used as a function. Given a timeseries or trajectory (i.e. StateSpaceSet) s and calling\n\nembedding(s, n)\n\nwill create the delay vector of the n-th point of s in the embedded space using generalized embedding (see genembed).\n\njs is ignored for timeseries input s (since all entries of js must be 1 in this case) and in addition js defaults to (1, ..., 1) for all τ.\n\nBe very careful when choosing n, because @inbounds is used internally. Use τrange!\n\n\n\n\n\n","category":"type"},{"location":"embed/#StateSpaceSet-reference","page":"Delay coordinates embedding","title":"StateSpaceSet reference","text":"","category":"section"},{"location":"embed/","page":"Delay coordinates embedding","title":"Delay coordinates embedding","text":"StateSpaceSet","category":"page"},{"location":"embed/#StateSpaceSets.StateSpaceSet","page":"Delay coordinates embedding","title":"StateSpaceSets.StateSpaceSet","text":"StateSpaceSet{D, T} <: AbstractStateSpaceSet{D,T}\n\nA dedicated interface for sets in a state space. It is an ordered container of equally-sized points of length D. Each point is represented by SVector{D, T}. The data are a standard Julia Vector{SVector}, and can be obtained with vec(ssset::StateSpaceSet). Typically the order of points in the set is the time direction, but it doesn't have to be.\n\nWhen indexed with 1 index, StateSpaceSet is like a vector of points. When indexed with 2 indices it behaves like a matrix that has each of the columns be the timeseries of each of the variables. When iterated over, it iterates over its contained points. See description of indexing below for more.\n\nStateSpaceSet also supports almost all sensible vector operations like append!, push!, hcat, eachrow, among others.\n\nDescription of indexing\n\nIn the following let i, j be integers, typeof(X) <: AbstractStateSpaceSet and v1, v2 be <: AbstractVector{Int} (v1, v2 could also be ranges, and for performance benefits make v2 an SVector{Int}).\n\nX[i] == X[i, :] gives the ith point (returns an SVector)\nX[v1] == X[v1, :], returns a StateSpaceSet with the points in those indices.\nX[:, j] gives the jth variable timeseries (or collection), as Vector\nX[v1, v2], X[:, v2] returns a StateSpaceSet with the appropriate entries (first indices being \"time\"/point index, while second being variables)\nX[i, j] value of the jth variable, at the ith timepoint\n\nUse Matrix(ssset) or StateSpaceSet(matrix) to convert. It is assumed that each column of the matrix is one variable. If you have various timeseries vectors x, y, z, ... pass them like StateSpaceSet(x, y, z, ...). You can use columns(dataset) to obtain the reverse, i.e. all columns of the dataset in a tuple.\n\n\n\n\n\n","category":"type"},{"location":"separated/#Separated-optimal-embedding","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"","category":"section"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"This page discusses and provides algorithms for estimating optimal parameters to do Delay Coordinates Embedding (DCE) with using the separated approach.","category":"page"},{"location":"separated/#Automated-function","page":"Separated optimal embedding","title":"Automated function","text":"","category":"section"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"optimal_separated_de","category":"page"},{"location":"separated/#DelayEmbeddings.optimal_separated_de","page":"Separated optimal embedding","title":"DelayEmbeddings.optimal_separated_de","text":"optimal_separated_de(s, method = \"afnn\", dmethod = \"mi_min\"; kwargs...) → 𝒟, τ, E\n\nProduce an optimal delay embedding 𝒟 of the given timeseries s by using the separated approach of first finding an optimal (and constant) delay time using estimate_delay with the given dmethod, and then an optimal embedding dimension, by calculating an appropriate statistic for each dimension d ∈ 1:dmax. Return the embedding 𝒟, the optimal delay time τ (the optimal embedding dimension d is just size(𝒟, 2)) and the actual statistic E used to estimate optimal d.\n\nNotice that E is a function of the embedding dimension, which ranges from 1 to dmax.\n\nFor calculating E to estimate the dimension we use the given method which can be:\n\n\"afnn\" (default) is Cao's \"Averaged False Nearest Neighbors\" method[Cao1997],   which gives a ratio of distances between nearest neighbors.\n\"ifnn\" is the \"Improved False Nearest Neighbors\" from Hegger & Kantz[Hegger1999],   which gives the fraction of false nearest neighbors.\n\"fnn\" is Kennel's \"False Nearest Neighbors\" method[Kennel1992], which gives   the number of points that cease to be \"nearest neighbors\" when the dimension   increases.\n\"f1nn\" is Krakovská's \"False First Nearest Neighbors\" method[Krakovská2015],   which gives the ratio of pairs of points that cease to be \"nearest neighbors\"   when the dimension increases.\n\nFor more details, see individual methods: delay_afnn, delay_ifnn, delay_fnn, delay_f1nn.\n\nwarn: Careful in automated methods\nWhile this method is automated if you want to be really sure of the results, you should directly calculate the statistic and plot its values versus the dimensions.\n\nKeyword arguments\n\nThe keywords\n\nτs = 1:100, dmax = 10\n\ndenote which delay times and embedding dimensions ds ∈ 1:dmax to consider when calculating optimal embedding. The keywords\n\nslope_thres = 0.05, stoch_thres = 0.1, fnn_thres = 0.05\n\nare specific to this function, see Description below. All remaining keywords are propagated to the low level functions:\n\nw, rtol, atol, τs, metric, r\n\nDescription\n\nWe estimate the optimal embedding dimension based on the given delay time gained from dmethod as follows: For Cao's method the optimal dimension is reached, when the slope of the E₁-statistic (output from \"afnn\") falls below the threshold slope_thres and the according stochastic test turns out to be false, i.e. if the E₂-statistic's first value is < 1 - stoch_thres.\n\nFor all the other methods we return the optimal embedding dimension when the corresponding FNN-statistic (output from \"ifnn\", \"fnn\" or \"f1nn\") falls below the fnn-threshold fnn_thres AND the slope of the statistic falls below the threshold slope_thres. Note that with noise contaminated time series, one might need to adjust fnn_thres according to the noise level.\n\nSee also the file test/compare_different_dimension_estimations.jl for a comparison.\n\n[Cao1997]: Liangyue Cao, Physica D, pp. 43-50 (1997)\n\n[Kennel1992]: M. Kennel et al., Phys. Review A 45(6), (1992).\n\n[Krakovská2015]: Anna Krakovská et al., J. Complex Sys. 932750 (2015)\n\n[Hegger1999]: Hegger & Kantz, Improved false nearest neighbor method to detect determinism in time series data. Physical Review E 60, 4970.\n\n\n\n\n\n","category":"function"},{"location":"separated/#Optimal-delay-time","page":"Separated optimal embedding","title":"Optimal delay time","text":"","category":"section"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"estimate_delay\nexponential_decay_fit","category":"page"},{"location":"separated/#DelayEmbeddings.estimate_delay","page":"Separated optimal embedding","title":"DelayEmbeddings.estimate_delay","text":"estimate_delay(s, method::String [, τs = 1:100]; kwargs...) -> τ\n\nEstimate an optimal delay to be used in embed. The method can be one of the following:\n\n\"ac_zero\" : first delay at which the auto-correlation function becomes <0.\n\"ac_min\" : delay of first minimum of the auto-correlation function.\n\"mi_min\" : delay of first minimum of mutual information of s with itself (shifted for various τs). Keywords nbins, binwidth are propagated into selfmutualinfo.\n\"exp_decay\" : exponential_decay_fit of the correlation function rounded  to an integer (uses least squares on c(t) = exp(-t/τ) to find τ).\n\"exp_extrema\" : same as above but the exponential fit is done to the absolute value of the local extrema of the correlation function.\n\nBoth the mutual information and correlation function (autocor) are computed only for delays τs. This means that the min methods can never return the first value of τs!\n\nThe method mi_min is significantly more accurate than the others and also returns good results for most timeseries. It is however the slowest method (but still quite fast!).\n\n\n\n\n\n","category":"function"},{"location":"separated/#DelayEmbeddings.exponential_decay_fit","page":"Separated optimal embedding","title":"DelayEmbeddings.exponential_decay_fit","text":"exponential_decay_fit(x, y, weight = :equal) -> τ\n\nPerform a least square fit of the form y = exp(-x/τ) and return τ. Taken from:  http://mathworld.wolfram.com/LeastSquaresFittingExponential.html. Assumes equal lengths of x, y and that y ≥ 0.\n\nTo use the method that gives more weight to small values of y, use weight = :small.\n\n\n\n\n\n","category":"function"},{"location":"separated/#Self-Mutual-Information","page":"Separated optimal embedding","title":"Self Mutual Information","text":"","category":"section"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"selfmutualinfo","category":"page"},{"location":"separated/#DelayEmbeddings.selfmutualinfo","page":"Separated optimal embedding","title":"DelayEmbeddings.selfmutualinfo","text":"selfmutualinfo(s, τs; kwargs...) → m\n\nCalculate the mutual information between the time series s and itself delayed by τ points for τ ∈ τs, using an improvement of the method outlined by Fraser & Swinney in[Fraser1986].\n\nDescription\n\nThe joint space of s and its τ-delayed image (sτ) is partitioned as a rectangular grid, and the mutual information is computed from the joint and marginal frequencies of s and sτ in the grid as defined in [1]. The mutual information values are returned in a vector m of the same length as τs.\n\nIf any of the optional keyword parameters is given, the grid will be a homogeneous partition of the space where s and sτ are defined. The margins of that partition will be divided in a number of bins equal to nbins, such that the width of each bin will be binwidth, and the range of nonzero values of s will be in the centre. If only of those two parameters is given, the other will be automatically calculated to adjust the size of the grid to the area where s and sτ are nonzero.\n\nIf no parameter is given, the space will be partitioned by a recursive bisection algorithm based on the method given in [1].\n\nNotice that the recursive method of [1] evaluates the joint frequencies of s and sτ in each cell resulting from a partition, and stops when the data points are uniformly distributed across the sub-partitions of the following levels. For performance and stability reasons, the automatic partition method implemented in this function is only used to divide the axes of the grid, using the marginal frequencies of s.\n\n[Fraser1986]: Fraser A.M. & Swinney H.L. \"Independent coordinates for strange attractors from mutual information\" Phys. Rev. A 33(2), 1986, 1134:1140.\n\n\n\n\n\n","category":"function"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"Notice that mutual information between two different timeseries x, y exists in JuliaDynamics as well, but in the package CausalityTools.jl. It is also trivial to define it yourself using entropy from ComplexityMeasures.","category":"page"},{"location":"separated/#Optimal-embedding-dimension","page":"Separated optimal embedding","title":"Optimal embedding dimension","text":"","category":"section"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"delay_afnn\ndelay_ifnn\ndelay_fnn\ndelay_f1nn\nDelayEmbeddings.stochastic_indicator","category":"page"},{"location":"separated/#DelayEmbeddings.delay_afnn","page":"Separated optimal embedding","title":"DelayEmbeddings.delay_afnn","text":"delay_afnn(s::AbstractVector, τ:Int, ds = 2:6; metric=Euclidean(), w = 0) → E₁\n\nCompute the parameter E₁ of Cao's \"averaged false nearest neighbors\" method for determining the minimum embedding dimension of the time series s, with a sequence of τ-delayed temporal neighbors.\n\nDescription\n\nGiven the scalar timeseries s and the embedding delay τ compute the values of E₁ for each embedding dimension d ∈ ds, according to Cao's Method (eq. 3 of[Cao1997]).\n\nThis quantity is a ratio of the averaged distances between the nearest neighbors of the reconstructed time series, which quantifies the increment of those distances when the embedding dimension changes from d to d+1.\n\nReturn the vector of all computed E₁s. To estimate a good value for d from this, find d for which the value E₁ saturates at some value around 1.\n\nNote: This method does not work for datasets with perfectly periodic signals.\n\nw is the Theiler window.\n\nSee also: optimal_separated_de and stochastic_indicator.\n\n\n\n\n\n","category":"function"},{"location":"separated/#DelayEmbeddings.delay_ifnn","page":"Separated optimal embedding","title":"DelayEmbeddings.delay_ifnn","text":"delay_ifnn(s::Vector, τ::Int, ds = 1:10; kwargs...) → `FNNs`\n\nCompute and return the FNNs-statistic for the time series s and a uniform time delay τ and embedding dimensions ds after [Hegger1999]. In this notation γ ∈ γs = d-1, if d is the embedding dimension. This fraction tends to 0 when the optimal embedding dimension with an appropriate lag is reached.\n\nKeywords\n\n*r = 2: Obligatory threshold, which determines the maximum tolerable spreading     of trajectories in the reconstruction space. *metric = Euclidean: The norm used for distance computations. *w = 1 = The Theiler window.\n\nSee also: optimal_separated_de.\n\n\n\n\n\n","category":"function"},{"location":"separated/#DelayEmbeddings.delay_fnn","page":"Separated optimal embedding","title":"DelayEmbeddings.delay_fnn","text":"delay_fnn(s::AbstractVector, τ:Int, ds = 2:6; rtol=10.0, atol=2.0) → FNNs\n\nCalculate the number of \"false nearest neighbors\" (FNNs) of the datasets created from s with embed(s, d, τ) for d ∈ ds.\n\nDescription\n\nGiven a dataset made by embed(s, d, τ) the \"false nearest neighbors\" (FNN) are the pairs of points that are nearest to each other at dimension d, but are separated at dimension d+1. Kennel's criteria for detecting FNN are based on a threshold for the relative increment of the distance between the nearest neighbors (rtol, eq. 4 in[Kennel1992]), and another threshold for the ratio between the increased distance and the \"size of the attractor\" (atol, eq. 5 in[Kennel1992]). These thresholds are given as keyword arguments.\n\nThe returned value is a vector with the number of FNN for each γ ∈ γs. The optimal value for γ is found at the point where the number of FNN approaches zero.\n\nSee also: optimal_separated_de.\n\n\n\n\n\n","category":"function"},{"location":"separated/#DelayEmbeddings.delay_f1nn","page":"Separated optimal embedding","title":"DelayEmbeddings.delay_f1nn","text":"delay_f1nn(s::AbstractVector, τ::Int, ds = 2:6; metric = Euclidean())\n\nCalculate the ratio of \"false first nearest neighbors\" (FFNN) of the datasets created from s with embed(s, d, τ) for d ∈ ds.\n\nDescription\n\nGiven a dataset made by embed(s, d, τ) the \"false first nearest neighbors\" (FFNN) are the pairs of points that are nearest to each other at dimension d that cease to be nearest neighbors at dimension d+1.\n\nThe returned value is a vector with the ratio between the number of FFNN and the number of points in the dataset for each d ∈ ds. The optimal value for d is found at the point where this ratio approaches zero.\n\nSee also: optimal_separated_de.\n\n\n\n\n\n","category":"function"},{"location":"separated/#DelayEmbeddings.stochastic_indicator","page":"Separated optimal embedding","title":"DelayEmbeddings.stochastic_indicator","text":"stochastic_indicator(s::AbstractVector, τ:Int, ds = 2:5) -> E₂s\n\nCompute an estimator for apparent randomness in a delay embedding with ds dimensions.\n\nDescription\n\nGiven the scalar timeseries s and the embedding delay τ compute the values of E₂ for each d ∈ ds, according to Cao's Method (eq. 5 of [Cao1997]).\n\nUse this function to confirm that the input signal is not random and validate the results of delay_afnn. In the case of random signals, it should be E₂ ≈ 1 ∀ d.\n\n\n\n\n\n","category":"function"},{"location":"separated/#Example","page":"Separated optimal embedding","title":"Example","text":"","category":"section"},{"location":"separated/","page":"Separated optimal embedding","title":"Separated optimal embedding","text":"using DelayEmbeddings, CairoMakie\nusing DynamicalSystemsBase\n\nfunction roessler_rule(u, p, t)\n    a, b, c = p\n    du1 = -u[2]-u[3]\n    du2 = u[1] + a*u[2]\n    du3 = b + u[3]*(u[1] - c)\n    return SVector(du1, du2, du3)\nend\nds = CoupledODEs(roessler_rule, [1, -2, 0.1], [0.2, 0.2, 5.7])\n\n# This trajectory is a chaotic attractor with fractal dim ≈ 2\n# therefore the set needs at least embedding dimension of 3\nX, tvec = trajectory(ds, 1000.0; Δt = 0.05)\nx = X[:, 1]\n\ndmax = 7\nfig = Figure()\nax = Axis(fig[1,1]; xlabel = \"embedding dimension\", ylabel = \"estimator\")\nfor (i, method) in enumerate([\"afnn\", \"fnn\", \"f1nn\", \"ifnn\"])\n    # Plot statistic used to estimate optimal embedding\n    # as well as the automated output embedding\n    𝒟, τ, E = optimal_separated_de(x, method; dmax)\n    lines!(ax, 1:dmax, E; label = method, marker = :circle, color = Cycled(i))\n    optimal_d = size(𝒟, 2)\n    ## Scatter the optimal embedding dimension as a lager marker\n    scatter!(ax, [optimal_d], [E[optimal_d]];\n        color = Cycled(i), markersize = 30\n    )\nend\naxislegend(ax)\nfig","category":"page"},{"location":"unified/#Unified-optimal-embedding","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"","category":"section"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"Unified approaches try to create an optimal embedding by in parallel optimizing what combination of delay times and embedding dimensions suits best.","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"In addition, the unified approaches are the only ones that can accommodate multi-variate inputs. This means that if you have multiple measured input timeseries, you should be able to take advantage of all of them for the best possible embedding of the dynamical system's set.","category":"page"},{"location":"unified/#An-example","page":"Unified optimal embedding","title":"An example","text":"","category":"section"},{"location":"unified/#Univariate-input","page":"Unified optimal embedding","title":"Univariate input","text":"","category":"section"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"In following we illustrate the most recent unified optimal embedding method, called PECUZAL, on three examples (see pecuzal_embedding). We start with a univariate case, i.e. we only feed in one time series, here the x-component of the Lorenz system.","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"using DynamicalSystemsBase # to simulate Lorenz63\n\nfunction lorenz_rule(u, p, t)\n    σ = p[1]; ρ = p[2]; β = p[3]\n    du1 = σ*(u[2]-u[1])\n    du2 = u[1]*(ρ-u[3]) - u[2]\n    du3 = u[1]*u[2] - β*u[3]\n    return SVector(du1, du2, du3)\nend\n\nlo = CoupledODEs(lorenz_rule, [1.0, 1.0, 50.0], [10, 28, 8/3])\ntr, tvec = trajectory(lo, 100; Δt = 0.01, Ttr = 10)","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"using DelayEmbeddings\ns = vec(tr[:, 1]) # input timeseries = x component of Lorenz\ntheiler = estimate_delay(s, \"mi_min\") # estimate a Theiler window\nTmax = 100 # maximum possible delay\n\nY, τ_vals, ts_vals, Ls, εs = pecuzal_embedding(s; τs = 0:Tmax , w = theiler, econ = true)\n\nprintln(\"τ_vals = \", τ_vals)\nprintln(\"Ls = \", Ls)\nprintln(\"L_total_uni: $(sum(Ls))\")","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"The output reveals that PECUZAL suggests a 3-dimensional embedding out of the un-lagged time series as the 1st component of the reconstruction, the time series lagged by 18 samples as the 2nd component and the time series lagged by 9 samples as the 3rd component. In the third embedding cycle there is no ΔL<0 and the algorithm terminates. The result after two successful embedding cycles is the 3-dimensional embedding Y which is also returned. The total obtained decrease of ΔL throughout all encountered embedding cycles has been ~ -1.24.","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"We can also look at continuity statistic","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"using CairoMakie\n\nfig = Figure()\nax = Axis(fig[1,1])\nlines!(εs[:,1], label=\"1st emb. cycle\")\nscatter!([τ_vals[2]], [εs[τ_vals[2],1]])\nlines!(εs[:,2], label=\"2nd emb. cycle\")\nscatter!([τ_vals[3]], [εs[τ_vals[3],2]])\nlines!(εs[:,3], label=\"3rd emb. cycle\")\nax.title = \"Continuity statistics PECUZAL Lorenz\"\nax.xlabel = \"delay τ\"\nax.ylabel = \"⟨ε⋆⟩\"\naxislegend(ax)\nfig","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"The picked delay values are marked with filled circles. As already mentioned, the third embedding cycle did not contribute to the embedding, i.e. there has been no delay value chosen.","category":"page"},{"location":"unified/#Multivariate-input","page":"Unified optimal embedding","title":"Multivariate input","text":"","category":"section"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"Similar to the approach in the preceding example, we now highlight the capability of the PECUZAL embedding method for a multivariate input. The idea is now to feed in all three time series to the algorithm, even though this is a very far-from-reality example. We already have an adequate representation of the system we want to reconstruct, namely the three time series from the numerical integration. But let us see what PECUZAL suggests for a reconstruction.","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"# compute Theiler window\nw1 = estimate_delay(tr[:,1], \"mi_min\")\nw2 = estimate_delay(tr[:,2], \"mi_min\")\nw3 = estimate_delay(tr[:,3], \"mi_min\")\nw = max(w1,w2,w3)\nY_m, τ_vals_m, ts_vals_m, = pecuzal_embedding(tr; τs = 0:Tmax , w = theiler, econ = true)\n\nprintln(τ_vals_m)\nprintln(ts_vals_m)","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"[0, 12, 0, 84, 69, 56]\n[3, 1, 1, 1, 1, 1]","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"PECUZAL returns a 6-dimensional embedding using the un-lagged z- and x-component as 1st and 3rd component of the reconstruction vectors, as well as the x-component lagged by 12, 79, 64, and 53 samples. The total decrease of ΔL is ~-1.64, and thus, way smaller compared to the univariate case, as we would expect it. Nevertheless, the main contribution to this increase is made by the first two embedding cycles. For suppressing embedding cycles, which yield negligible - but negative - ΔL-values one can use the keyword argument L_threshold","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"Y_mt, τ_vals_mt, ts_vals_mt, Ls_mt, εs_mt = pecuzal_embedding(tr;\n    τs = 0:Tmax, L_threshold = 0.2, w = theiler, econ = true\n)\n\nprintln(τ_vals_mt)\nprintln(ts_vals_mt)","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"As you can see here the algorithm stopped already at 3-dimensional embedding.","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"Let's plot these three components:","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"ts_str = [\"x\", \"y\", \"z\"]\n\nfig = Figure(resolution = (1000,500) )\nax1 = Axis3(fig[1,1], title = \"PECUZAL reconstructed\")\nlines!(ax1, Y_mt[:,1], Y_mt[:,2], Y_mt[:,3]; linewidth = 1.0)\nax1.xlabel = \"$(ts_str[ts_vals_mt[1]])(t+$(τ_vals_mt[1]))\"\nax1.ylabel = \"$(ts_str[ts_vals_mt[2]])(t+$(τ_vals_mt[2]))\"\nax1.zlabel = \"$(ts_str[ts_vals_mt[3]])(t+$(τ_vals_mt[3]))\"\nax1.azimuth = 3π/2 + π/4\n\nax2 = Axis3(fig[1,2], title = \"original\")\nlines!(ax2, tr[:,1], tr[:,2], tr[:,3]; linewidth = 1.0, color = Cycled(2))\nax2.xlabel = \"x(t)\"\nax2.ylabel = \"y(t)\"\nax2.zlabel = \"z(t)\"\nax2.azimuth = π/2 + π/4\nfig","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"Finally we show what PECUZAL does with a non-deterministic source:","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"using Random\n\n# Dummy input\nRandom.seed!(1234)\nd1 = randn(1000)\nd2 = rand(1000)\nTmax = 100\ndummy_set = Dataset(d1,d2)\n\nw1 = estimate_delay(d1, \"mi_min\")\nw2 = estimate_delay(d2, \"mi_min\")\ntheiler = min(w1, w2)\n\nY_d, τ_vals_d, ts_vals_d, Ls_d , ε★_d = pecuzal_embedding(dummy_set; τs = 0:Tmax , w = theiler, econ = true)\n\nsize(Y_d)","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"So, no (proper) embedding is done.","category":"page"},{"location":"unified/#All-unified-algorithms","page":"Unified optimal embedding","title":"All unified algorithms","text":"","category":"section"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"Several algorithms have been created to implement a unified approach to delay coordinates embedding. You can find some implementations below:","category":"page"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"pecora\nuzal_cost\ngarcia_almeida_embedding\nmdop_embedding\npecuzal_embedding","category":"page"},{"location":"unified/#DelayEmbeddings.pecora","page":"Unified optimal embedding","title":"DelayEmbeddings.pecora","text":"pecora(s, τs, js; kwargs...) → ⟨ε★⟩, ⟨Γ⟩\n\nCompute the (average) continuity statistic ⟨ε★⟩ and undersampling statistic ⟨Γ⟩ according to Pecora et al.[Pecoral2007] (A unified approach to attractor reconstruction), for a given input s (timeseries or StateSpaceSet) and input generalized embedding defined by (τs, js), according to genembed. The continuity statistic represents functional independence between the components of the existing embedding and one additional timeseries. The returned results are matrices with size TxJ.\n\nKeyword arguments\n\ndelays = 0:50: Possible time delay values delays (in sampling time units). For each of the τ's in delays the continuity-statistic ⟨ε★⟩ gets computed. If undersampling = true (see further down), also the undersampling statistic ⟨Γ⟩ gets returned for all considered delay values.\nJ = 1:dimension(s): calculate for all timeseries indices in J. If input s is a timeseries, this is always just 1.\nsamplesize::Real = 0.1: determine the fraction of all phase space points (=length(s)) to be considered (fiducial points v) to average ε★ to produce ⟨ε★⟩, ⟨Γ⟩\nK::Int = 13: the amount of nearest neighbors in the δ-ball (read algorithm description). Must be at least 8 (in order to gurantee a valid statistic). ⟨ε★⟩ is computed taking the minimum result over all k ∈ K.\nmetric = Chebyshev(): metrix with which to find nearest neigbhors in the input embedding (ℝᵈ space, d = length(τs)).\nw = 1: Theiler window (neighbors in time with index w close to the point, that are excluded from being true neighbors). w=0 means to exclude only the point itself, and no temporal neighbors.\nundersampling = false : whether to calculate the undersampling statistic or not (if not, zeros are returned for ⟨Γ⟩). Calculating ⟨Γ⟩ is thousands of times slower than ⟨ε★⟩.\ndb::Int = 100: Amount of bins used into calculating the histograms of each timeseries (for the undersampling statistic).\nα::Real = 0.05: The significance level for obtaining the continuity statistic\np::Real = 0.5: The p-parameter for the binomial distribution used for the computation of the continuity statistic.\n\nDescription\n\nNotice that the full algorithm is too large to discuss here, and is written in detail (several pages!) in the source code of pecora.\n\n[Pecora2007]: Pecora, L. M., Moniz, L., Nichols, J., & Carroll, T. L. (2007). A unified approach to attractor reconstruction. Chaos 17(1).\n\n\n\n\n\n","category":"function"},{"location":"unified/#DelayEmbeddings.uzal_cost","page":"Unified optimal embedding","title":"DelayEmbeddings.uzal_cost","text":"uzal_cost(Y::StateSpaceSet; kwargs...) → L\n\nCompute the L-statistic L for input dataset Y according to Uzal et al.[Uzal2011], based on theoretical arguments on noise amplification, the complexity of the reconstructed attractor and a direct measure of local stretch which constitutes an irrelevance measure. It serves as a cost function of a state space trajectory/embedding and therefore allows to estimate a \"goodness of a embedding\" and also to choose proper embedding parameters, while minimizing L over the parameter space. For receiving the local cost function L_local (for each point in state space - not averaged), use uzal_cost_local(...).\n\nKeyword arguments\n\nsamplesize = 0.5: Number of considered fiducial points v as a fraction of input state space trajectory Y's length, in order to average the conditional variances and neighborhood sizes (read algorithm description) to produce L.\nK = 3: the amount of nearest neighbors considered, in order to compute σ_k^2 (read algorithm description). If given a vector, minimum result over all k ∈ K is returned.\nmetric = Euclidean(): metric used for finding nearest neigbhors in the input state space trajectory `Y.\nw = 1: Theiler window (neighbors in time with index w close to the point, that are excluded from being true neighbors). w=0 means to exclude only the point itself, and no temporal neighbors.\nTw = 40: The time horizon (in sampling units) up to which E_k^2 gets computed and averaged over (read algorithm description).\n\nDescription\n\nThe L-statistic is based on theoretical arguments on noise amplification, the complexity of the reconstructed attractor and a direct measure of local stretch which constitutes an irrelevance measure. Technically, it is the logarithm of the product of σ-statistic and a normalization statistic α:\n\nL = log10(σ*α)\n\nThe σ-statistic is computed as follows. σ = √σ² = √(E²/ϵ²). E² approximates the conditional variance at each point in state space and for a time horizon T ∈ Tw, using K nearest neighbors. For each reference point of the state space trajectory, the neighborhood consists of the reference point itself and its K+1 nearest neighbors. E² measures how strong a neighborhood expands during T time steps. E² is averaged over many time horizons T = 1:Tw. Consequently, ϵ² is the size of the neighborhood at the reference point itself and is defined as the mean pairwise distance of the neighborhood. Finally, σ² gets averaged over a range of reference points on the attractor, which is controlled by samplesize. This is just for performance reasons and the most accurate result will obviously be gained when setting samplesize=1.0\n\nThe α-statistic is a normalization factor, such that σ's from different embeddings can be compared. α² is defined as the inverse of the sum of the inverse of all ϵ²'s for all considered reference points.\n\n[Uzal2011]: Uzal, L. C., Grinblat, G. L., Verdes, P. F. (2011). Optimal reconstruction of dynamical systems: A noise amplification approach. Physical Review E 84, 016223.\n\n\n\n\n\n","category":"function"},{"location":"unified/#DelayEmbeddings.garcia_almeida_embedding","page":"Unified optimal embedding","title":"DelayEmbeddings.garcia_almeida_embedding","text":"garcia_almeida_embedding(s; kwargs...) → Y, τ_vals, ts_vals, FNNs ,NS\n\nA unified approach to properly embed a time series (Vector type) or a set of time series (StateSpaceSet type) based on the papers of Garcia & Almeida [Garcia2005a],[Garcia2005b].\n\nKeyword arguments\n\nτs= 0:50: Possible delay values τs (in sampling time units). For each of the τs's the N-statistic gets computed.\nw::Int = 1: Theiler window (neighbors in time with index w close to the point, that are excluded from being true neighbors). w=0 means to exclude only the point itself, and no temporal neighbors.\nr1 = 10: The threshold, which defines the factor of tolerable stretching for the d_E1-statistic.\nr2 = 2: The threshold for the tolerable relative increase of the distance between the nearest neighbors, when increasing the embedding dimension.\nfnn_thres= 0.05: A threshold value defining a sufficiently small fraction of false nearest neighbors, in order to the let algorithm terminate and stop the embedding procedure (`0 ≤ fnn_thres < 1).\nT::Int = 1: The forward time step (in sampling units) in order to compute the d_E2-statistic (see algorithm description). Note that in the paper this is not a free parameter and always set to T=1.\nmetric = Euclidean(): metric used for finding nearest neigbhors in the input phase space trajectory Y.\nmax_num_of_cycles = 50: The algorithm will stop after that many cycles no matter what.\n\nDescription\n\nThe method works iteratively and gradually builds the final embedding vectors Y. Based on the N-statistic the algorithm picks an optimal delay value τ for each embedding cycle as the first local minimum of N. In case of multivariate embedding, i.e. when embedding a set of time series (s::StateSpaceSet), the optimal delay value τ is chosen as the first minimum from all minimum's of all considered N-statistics for each embedding cycle. The range of considered delay values is determined in τs and for the nearest neighbor search we respect the Theiler window w. After each embedding cycle the FNN-statistic FNNs [Hegger1999][Kennel1992] is being checked and as soon as this statistic drops below the threshold fnn_thres, the algorithm breaks. In order to increase the  practability of the method the algorithm also breaks, when the FNN-statistic FNNs increases . The final embedding vector is stored in Y (StateSpaceSet). The chosen delay values for each embedding cycle are stored in the τ_vals and the according time series number chosen for the according delay value in τ_vals is stored in ts_vals. For univariate embedding (s::Vector) ts_vals is a vector of ones of length τ_vals, because there is simply just one time series to choose from. The function also returns the N-statistic NS for each embedding cycle as an Array of Vectors.\n\nNotice that we were not able to reproduce the figures from the papers with our implementation (which nevertheless we believe is the correct one).\n\n[Garcia2005a]: Garcia, S. P., Almeida, J. S. (2005). Nearest neighbor embedding with different time delays. Physical Review E 71, 037204.\n\n[Garcia2005b]: Garcia, S. P., Almeida, J. S. (2005). Multivariate phase space reconstruction by nearest neighbor embedding with different time delays. Physical Review E 72, 027205.\n\n\n\n\n\n","category":"function"},{"location":"unified/#DelayEmbeddings.mdop_embedding","page":"Unified optimal embedding","title":"DelayEmbeddings.mdop_embedding","text":"mdop_embedding(s::Vector; kwargs...) → Y, τ_vals, ts_vals, FNNs, βS\n\nMDOP (for \"maximizing derivatives on projection\") is a unified approach to properly embed a timeseries or a set of timeseries (StateSpaceSet) based on the paper of Chetan Nichkawde [Nichkawde2013].\n\nKeyword arguments\n\nτs= 0:50: Possible delay values τs. For each of the τs's the β-statistic gets computed.\nw::Int = 1: Theiler window (neighbors in time with index w close to the point, that are excluded from being true neighbors). w=0 means to exclude only the point itself, and no temporal neighbors.\nfnn_thres::Real= 0.05: A threshold value defining a sufficiently small fraction of false nearest neighbors, in order to the let algorithm terminate and stop the embedding procedure (`0 ≤ fnn_thres < 1).\nr::Real = 2: The threshold for the tolerable relative increase of the distance between the nearest neighbors, when increasing the embedding dimension.\nmax_num_of_cycles = 50: The algorithm will stop after that many cycles no matter what.\n\nDescription\n\nThe method works iteratively and gradually builds the final embedding Y. Based on the beta_statistic the algorithm picks an optimal delay value τ for each embedding cycle as the global maximum of β. In case of multivariate embedding, i.e. when embedding a set of time series (s::StateSpaceSet), the optimal delay value τ is chosen as the maximum from all maxima's of all considered β-statistics for each possible timeseries. The range of considered delay values is determined in τs and for the nearest neighbor search we respect the Theiler window w.\n\nAfter each embedding cycle the FNN-statistic FNNs [Hegger1999][Kennel1992] is being checked and as soon as this statistic drops below the threshold fnn_thres, the algorithm terminates. In order to increase the practability of the method the algorithm also terminates when the FNN-statistic FNNs increases.\n\nThe final embedding is returned as Y. The chosen delay values for each embedding cycle are stored in the τ_vals and the according timeseries index chosen for the the respective according delay value in τ_vals is stored in ts_vals. βS, FNNs are returned for clarity and double-checking, since they are computed anyway. In case of multivariate embedding, βS will store all β-statistics for all available time series in each embedding cycle. To double-check the actual used β-statistics in an embedding cycle 'k', simply βS[k][:,ts_vals[k+1]].\n\n[Nichkawde2013]: Nichkawde, Chetan (2013). Optimal state-space reconstruction using derivatives on projected manifold. Physical Review E 87, 022905.\n\n[Hegger1999]: Hegger, Rainer and Kantz, Holger (1999). Improved false nearest neighbor method to detect determinism in time series data. Physical Review E 60, 4970.\n\n[Kennel1992]: Kennel, M. B., Brown, R., Abarbanel, H. D. I. (1992). Determining embedding dimension for state-space reconstruction using a geometrical construction. Phys. Rev. A 45, 3403.\n\n\n\n\n\n","category":"function"},{"location":"unified/#DelayEmbeddings.pecuzal_embedding","page":"Unified optimal embedding","title":"DelayEmbeddings.pecuzal_embedding","text":"pecuzal_embedding(s; kwargs...) → Y, τ_vals, ts_vals, ΔLs, ⟨ε★⟩\n\nA unified approach to properly embed a timeseries or a set of timeseries (StateSpaceSet) based on the recent PECUZAL algorithm due to Kraemer et al.[Kraemer2021].\n\nFor more details, see the description below.\n\nKeyword arguments\n\nτs = 0:50: Possible delay values τs (in sampling time units). For each of the τs's the continuity statistic ⟨ε★⟩ gets computed and further processed in order to find optimal delays τᵢ for each embedding cycle i.\nw::Int = 0: Theiler window (neighbors in time with index w close to the point, that are excluded from being true neighbors). w=0 means to exclude only the point itself, and no temporal neighbors.\nsamplesize::Real = 1.0: Fraction of state space points to be considered (fiducial points v) to average ε★ over, in order to produce ⟨ε★⟩. Lower fraction value decreases accuracy as well as computation time.\nK::Int = 13: the amount of nearest neighbors in the δ-ball (read algorithm description). Must be at least 8 (in order to gurantee a valid statistic). ⟨ε★⟩ is computed taking the minimum result over all k ∈ K.\nKNN::Int = 3: the amount of nearest neighbors considered, in order to compute σk^2 (read algorithm description [`uzalcost]@ref). If given a vector, the minimum result over allknn ∈ KNN` is returned.\nL_threshold::Real = 0: The algorithm breaks, when this threshold is exceeded by ΔL in an embedding cycle (set as a positive number, i.e. an absolute value of ΔL).\nα::Real = 0.05: The significance level for obtaining the continuity statistic\np::Real = 0.5: The p-parameter for the binomial distribution used for the computation of the continuity statistic ⟨ε★⟩.\nmax_cycles = 50: The algorithm will stop after that many cycles no matter what.\necon::Bool = false: Economy-mode for L-statistic computation. Instead of computing L-statistics for time horizons 2:Tw, here we only compute them for 2:2:Tw, see description for further details.\nverbose = true: Print information about the process.\n\nDescription\n\nThe method works iteratively and gradually builds the final embedding vectors Y. Based on the ⟨ε★⟩-statistic (of pecora) the algorithm picks an optimal delay value τᵢ for each embedding cycle i. For achieving that, we take the inpute time series s, denoted as the actual phase space trajectory Y_actual and compute the continuity statistic ⟨ε★⟩.\n\nEach local maxima in ⟨ε★⟩ is used for constructing a candidate embedding trajectory Y_trial with a delay corresponding to that specific peak in ⟨ε★⟩.\nWe then compute the L-statistic (of uzal_cost) for Y_trial (L-trial) and Y_actual (L_actual) for increasing prediction time horizons (free parameter in the L-statistic) and save the maximum difference max(L-trial - L_actual) as ΔL (Note that this is a negative number, since the L-statistic decreases with better reconstructions).\nWe pick the τ-value, for which ΔL is minimal (=maximum decrease of the overall L-value) and construct the actual embedding trajectory Y_actual (steps 1.-3. correspond to an embedding cycle).\nWe repeat steps 1.-3. with Y_actual as input and stop the algorithm when ΔL is > 0, i.e. when and additional embedding component would not lead to a lower overall L-value. Y_actual -> Y.\n\nIn case of multivariate embedding, i.e. when embedding a set of M time series (s::StateSpaceSet), in each embedding cycle the continuity statistic ⟨ε★⟩ gets computed for all M time series available. The optimal delay value τ in each embedding cycle is chosen as the peak/τ-value for which ΔL is minimal under all available peaks and under all M ⟨ε★⟩'s. In the first embedding cycle there will be M² different ⟨ε★⟩'s to consider, since it is not clear a priori which time series of the input should consitute the first component of the embedding vector and form Y_actual.\n\nThe range of considered delay values is determined in τs and for the nearest neighbor search we respect the Theiler window w. The final embedding vector is stored in Y (StateSpaceSet). The chosen delay values for each embedding cycle are stored in τ_vals and the according time series numbers chosen for each delay value in τ_vals are stored in ts_vals. For univariate embedding (s::Vector) ts_vals is a vector of ones of length τ_vals, because there is simply just one timeseries to choose from. The function also returns the ΔLs-values for each embedding cycle and the continuity statistic ⟨ε★⟩ as an Array of Vectors.\n\nFor distance computations the Euclidean norm is used.\n\n[Kraemer2021]: Kraemer, K.H., Datseris, G., Kurths, J., Kiss, I.Z., Ocampo-Espindola, Marwan, N. (2021) A unified and automated approach to attractor reconstruction. New Journal of Physics 23(3), 033017.\n\n\n\n\n\n","category":"function"},{"location":"unified/#Low-level-functions-of-unified-approach","page":"Unified optimal embedding","title":"Low-level functions of unified approach","text":"","category":"section"},{"location":"unified/","page":"Unified optimal embedding","title":"Unified optimal embedding","text":"DelayEmbeddings.n_statistic\nDelayEmbeddings.beta_statistic\nDelayEmbeddings.mdop_maximum_delay","category":"page"},{"location":"unified/#DelayEmbeddings.n_statistic","page":"Unified optimal embedding","title":"DelayEmbeddings.n_statistic","text":"n_statistic(Y, s; kwargs...) → N, d_E1\n\nPerform one embedding cycle according to the method proposed in [Garcia2005a] for a given phase space trajectory Y (of type StateSpaceSet) and a time series s (of typeVector). Return the proposed N-StatisticNand all nearest neighbor distancesd_E1for each point of the input phase space trajectoryY. Note thatY` is a single time series in case of the first embedding cycle.\n\nKeyword arguments\n\nτs= 0:50: Considered delay values τs (in sampling time units). For each of the τs's the N-statistic gets computed.\nr = 10: The threshold, which defines the factor of tolerable stretching for the d_E1-statistic (see algorithm description).\nT::Int = 1: The forward time step (in sampling units) in order to compute the d_E2-statistic (see algorithm description). Note that in the paper this is not a free parameter and always set to T=1.\nw::Int = 0: Theiler window (neighbors in time with index w close to the point, that are excluded from being true neighbors). w=0 means to exclude only the point itself, and no temporal neighbors. Note that in the paper this is not a free parameter and always w=0.\nmetric = Euclidean(): metric used for finding nearest neigbhors in the input phase space trajectory Y.\n\nDescription\n\nFor a range of possible delay values τs one constructs a temporary embedding matrix. That is, one concatenates the input phase space trajectory Y with the τ-lagged input time series s. For each point on the temporary trajectory one computes its nearest neighbor, which is denoted as the d_E1-statistic for a specific τ. Now one considers the distance between the reference point and its nearest neighbor T sampling units ahead and calls this statistic d_E2. [Garcia2005a] strictly use T=1, so they forward each reference point and its corresponding nearest neighbor just by one (!) sampling unit. Here it is a free parameter.\n\nThe N-statistic is then the fraction of d_E2/d_E1-pairs which exceed a threshold r.\n\nPlotted vs. the considered τs-values it is proposed to pick the τ-value for this embedding cycle as the value, where N has its first local minimum.\n\n[Garcia2005a]: Garcia, S. P., Almeida, J. S. (2005). Nearest neighbor embedding with different time delays. Physical Review E 71, 037204.\n\n\n\n\n\n","category":"function"},{"location":"unified/#DelayEmbeddings.beta_statistic","page":"Unified optimal embedding","title":"DelayEmbeddings.beta_statistic","text":"beta_statistic(Y::StateSpaceSet, s::Vector) [, τs, w]) → β\n\nCompute the β-statistic β for input state space trajectory Y and a timeseries s according to Nichkawde [Nichkawde2013], based on estimating derivatives on a projected manifold. For a range of delay values τs, β gets computed and its maximum over all considered τs serves as the optimal delay considered in this embedding cycle.\n\nArguments τs, w as in mdop_embedding.\n\nDescription\n\nThe β-statistic is based on the geometrical idea of maximal unfolding of the reconstructed attractor and is tightly related to the False Nearest Neighbor method ([Kennel1992]). In fact the method eliminates the maximum amount of false nearest neighbors in each embedding cycle. The idea is to estimate the absolute value of the directional derivative with respect to a possible new dimension in the reconstruction process, and with respect to the nearest neighbor, for all points of the state space trajectory:\n\nϕ'(τ) = Δϕd(τ) / Δxd\n\nΔxd is simply the Euclidean nearest neighbor distance for a reference point with respect to the given Theiler window w. Δϕd(τ) is the distance of the reference point to its nearest neighbor in the one dimensional time series s, for the specific τ. Δϕ_d(τ) = |s(i+τ)-s(j+τ)|, with i being the index of the considered reference point and j the index of its nearest neighbor.\n\nFinally,\n\nβ = log β(τ) = ⟨log₁₀ ϕ'(τ)⟩ ,\n\nwith ⟨.⟩ being the mean over all reference points. When one chooses the maximum of β over all considered τ's, one obtains the optimal delay value for this embedding cycle. Note that in the first embedding cycle, the input state space trajectory Y can also be just a univariate time series.\n\n[Nichkawde2013]: Nichkawde, Chetan (2013). Optimal state-space reconstruction using derivatives on projected manifold. Physical Review E 87, 022905.\n\n[Kennel1992]: Kennel, M. B., Brown, R., Abarbanel, H. D. I. (1992). Determining embedding dimension for state-space reconstruction using a geometrical construction. Phys. Rev. A 45, 3403.\n\n\n\n\n\n","category":"function"},{"location":"unified/#DelayEmbeddings.mdop_maximum_delay","page":"Unified optimal embedding","title":"DelayEmbeddings.mdop_maximum_delay","text":"mdop_maximum_delay(s, tw = 1:50, samplesize = 1.0)) -> τ_max, L\n\nCompute an upper bound for the search of optimal delays, when using mdop_embedding mdop_embedding or beta_statistic beta_statistic.\n\nDescription\n\nThe input time series s gets embedded with unit lag and increasing dimension, for dimensions (or time windows) tw (RangeObject). For each of such a time window the L-statistic from Uzal et al. [Uzal2011] will be computed. samplesize determines the fraction of points to be considered in the computation of L (see uzal_cost). When this statistic reaches its global minimum the maximum delay value τ_max gets returned. When s is a multivariate StateSpaceSet, τ_max will becomputed for all timeseries of that StateSpaceSet and the maximum value will be returned. The returned L-statistic has size (length(tw), size(s,2)).\n\n[Nichkawde2013]: Nichkawde, Chetan (2013). Optimal state-space reconstruction using derivatives on projected manifold. Physical Review E 87, 022905.\n\n[Uzal2011]: Uzal, L. C., Grinblat, G. L., Verdes, P. F. (2011). Optimal reconstruction of dynamical systems: A noise amplification approach. Physical Review E 84, 016223.\n\n\n\n\n\n","category":"function"},{"location":"#DelayEmbeddings.jl","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"","category":"section"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"DelayEmbeddings","category":"page"},{"location":"#DelayEmbeddings","page":"DelayEmbeddings.jl","title":"DelayEmbeddings","text":"DelayEmbeddings.jl\n\n(Image: ) (Image: ) (Image: ) (Image: CI) (Image: codecov) (Image: Package Downloads)\n\nA Julia package that provides a generic interface for performing delay coordinate embeddings, as well as cutting edge algorithms for creating optimal embeddings given some data. It can be used as a standalone package, or as part of DynamicalSystems.jl.\n\nTo install it, run import Pkg; Pkg.add(\"DelayEmbeddings\").\n\nAll further information is provided in the documentation, which you can either find online or build locally by running the docs/make.jl file.\n\n\n\n\n\n","category":"module"},{"location":"#Overview","page":"DelayEmbeddings.jl","title":"Overview","text":"","category":"section"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"note: Note\nThe documentation and the code of this package is parallelizing Chapter 6 of Nonlinear Dynamics, Datseris & Parlitz, Springer 2022.","category":"page"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"The package provides an interface to perform delay coordinates embeddings, as explained in homonymous page.","category":"page"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"There are two approaches for estimating optimal parameters to do delay embeddings:","category":"page"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"Separated, where one tries to find the best value for a delay time τ and then an optimal embedding dimension d.\nUnified, where at the same time an optimal combination of τ, d is found.","category":"page"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"The separated approach is something \"old school\", while recent scientific research has shifted almost exclusively to unified approaches. This page describes algorithms belonging to the separated approach, which is mainly done by the function optimal_separated_de.","category":"page"},{"location":"","page":"DelayEmbeddings.jl","title":"DelayEmbeddings.jl","text":"The unified approach is discussed in the Unified optimal embedding page.","category":"page"}]
}
